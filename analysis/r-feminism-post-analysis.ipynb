{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3be770b-c59c-410d-ae49-720dee113b18",
   "metadata": {},
   "source": [
    "# Analyzing Posts and Comments from r/feminism\n",
    "J. Nathan Matias, Dec 2024\n",
    "\n",
    "In support of this r/feminism study: https://osf.io/xu258\n",
    "\n",
    "Goals:\n",
    "- for the time period covered by the spring 2018 survey\n",
    "- create a dataset of comments and posts\n",
    "- report on:\n",
    "  - the number of newcomers per post (if possible)\n",
    "  - the number (or proportion?) of comments removed per post\n",
    "  - the number (or proportion?) of comments per post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3228a6b5-2bbc-4821-bf06-b28164e46dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import inspect, os, sys, copy, pytz, re, glob, csv, uuid, datetime, jsonlines, time, yaml, math\n",
    "from bloom_filter import BloomFilter\n",
    "\n",
    "os.environ['AIRBRAKE_API_KEY'] = \"ca826dbd1a4594241c239bba825edd9f\" ## EDIT BEFORER USING\n",
    "os.environ['AIRBRAKE_PROJECT_ID'] = \"-1\" ## EDIT BEFORE USING\n",
    "\n",
    "import simplejson as json\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt   # Matplotlib for plotting\n",
    "import matplotlib.dates as md\n",
    "from collections import Counter, defaultdict\n",
    "import csv, glob, heapq\n",
    "utc=pytz.UTC\n",
    "\n",
    "ENV = \"production\"\n",
    "os.environ['CS_ENV'] = 'production'\n",
    "BASE_DIR = \"/cs/civilservant-jupyter\"\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "with open(os.path.join(BASE_DIR, \"config\") + \"/{env}.json\".format(env=ENV), \"r\") as config:\n",
    "  DBCONFIG = json.loads(config.read())\n",
    "\n",
    "### LOAD SQLALCHEMY\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import text, and_, or_\n",
    "import sqlalchemy.orm.session\n",
    "import utils.common\n",
    "\n",
    "\n",
    "db_engine = create_engine(\"mysql://{user}:{password}@{host}/{database}\".format(\n",
    "    host = DBCONFIG['host'],\n",
    "    user = DBCONFIG['user'],\n",
    "    password = DBCONFIG['password'],\n",
    "    database = DBCONFIG['database']))\n",
    "DBSession = sessionmaker(bind=db_engine)\n",
    "db_session = DBSession()\n",
    "\n",
    "\n",
    "## LOAD MYSQLDB\n",
    "import MySQLdb\n",
    "db=MySQLdb.connect(host =   DBCONFIG['host'],   \n",
    "                   user =   DBCONFIG['user'],\n",
    "                   passwd = DBCONFIG['password'],\n",
    "                   db =     DBCONFIG['database'])\n",
    "cursor = db.cursor(MySQLdb.cursors.DictCursor)\n",
    "\n",
    "# ### LOAD PRAW\n",
    "# import reddit.connection\n",
    "# conn = reddit.connection.Connect(base_dir=BASE_DIR)\n",
    "# r = conn.connect()\n",
    "\n",
    "from app.models import *\n",
    "\n",
    "### FILTER OUT DEPRECATION WARNINGS ASSOCIATED WITH DECORATORS\n",
    "# https://github.com/ipython/ipython/issues/9242\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning, message='.*use @default decorator instead.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d58e78a-aceb-43d1-925f-f59b8ba8b394",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_id = \"2qr7i\"\n",
    "subreddit_name = \"feminism\"\n",
    "data_dir = \"./\"\n",
    "\n",
    "earliest_date = parser.parse(\"2018-01-1\")\n",
    "latest_date   = parser.parse(\"2018-04-17\")\n",
    "newcomer_begin_date = earliest_date - datetime.timedelta(days=30*6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68095187-9c12-4f7c-b1a5-2b12daf62b88",
   "metadata": {},
   "source": [
    "## Load Moderator Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "949fc76f-e1b7-4a2a-9fad-c991e5a5d3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15600 moderator actions loaded in 3103 seconds\n"
     ]
    }
   ],
   "source": [
    "recent_mod_actions = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for row in db_engine.execute(text(\"\"\"\n",
    "SELECT action_data FROM mod_actions \n",
    "    WHERE subreddit_id=\"{0}\" AND \n",
    "          created_utc >= \"{1}\" AND\n",
    "          created_utc <= \"{2}\"\n",
    "    ORDER BY created_utc;\n",
    "\"\"\".format(subreddit_id,\n",
    "           earliest_date,\n",
    "           latest_date +  datetime.timedelta(days=7)))):\n",
    "    mod_action = json.loads(row['action_data'])\n",
    "    mod_action['created'] = utc.localize(datetime.datetime.utcfromtimestamp(mod_action['created_utc']))\n",
    "    recent_mod_actions.append(mod_action)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"{0} moderator actions loaded in {1} seconds\".format(len(recent_mod_actions), int(end-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628add4b-7316-445a-aad7-0ce8b540c053",
   "metadata": {},
   "source": [
    "## Load Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0a2cdb5-a1b1-4f2b-8a35-913188affb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT * FROM comments \n",
      "    WHERE subreddit_id=\"2qr7i\" AND \n",
      "          created_utc >= \"2017-07-05 00:00:00\" AND\n",
      "          created_utc <= \"2018-04-17 00:00:00\";\n",
      "\n",
      "Loaded 7145 comments in 516 seconds\n"
     ]
    }
   ],
   "source": [
    "newcomer_comment_query = \"\"\"\n",
    "SELECT * FROM comments \n",
    "    WHERE subreddit_id=\"{0}\" AND \n",
    "          created_utc >= \"{1}\" AND\n",
    "          created_utc <= \"{2}\";\n",
    "\"\"\".format(subreddit_id,\n",
    "           newcomer_begin_date,\n",
    "           latest_date)\n",
    "\n",
    "print(newcomer_comment_query)\n",
    "\n",
    "all_accounts = set()\n",
    "all_comments = []\n",
    "count_dates = defaultdict(int)\n",
    "counter = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "cursor.execute(newcomer_comment_query)\n",
    "for row in cursor.fetchall():\n",
    "    if(isinstance(row['created_utc'], float)):\n",
    "        row['created'] = utc.localize(datetime.datetime.utcfromtimestamp(row['created_utc']))\n",
    "    else:\n",
    "        row['created'] = row['created_utc']\n",
    "    day_diff = (row['created'] - newcomer_begin_date).days\n",
    "    \n",
    "    all_accounts.add(row['user_id'])\n",
    "    all_comments.append(row)\n",
    "    count_dates[day_diff] += 1\n",
    "    counter += 1\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "print(\"Loaded {0} comments in {1} seconds\".format(counter, int(end-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74e6bda-7de0-4d3d-b7f2-bf311c3eebfa",
   "metadata": {},
   "source": [
    "### Load Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f33dbc9-ff7c-4134-a96a-587ca1a9f601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912 posts actions loaded in 0 seconds\n"
     ]
    }
   ],
   "source": [
    "all_posts = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for row in db_engine.execute(text(\"\"\"\n",
    "SELECT post_data FROM posts \n",
    "    WHERE subreddit_id=\"{0}\" AND \n",
    "          created >= \"{1}\" AND\n",
    "          created <= \"{2}\"\n",
    "    ORDER BY created;\n",
    "\"\"\".format(subreddit_id,\n",
    "           earliest_date,\n",
    "           latest_date))):\n",
    "    post = json.loads(row['post_data'])\n",
    "    post['created'] = utc.localize(datetime.datetime.utcfromtimestamp(post['created']))\n",
    "    all_posts.append(post)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"{0} posts actions loaded in {1} seconds\".format(len(all_posts), int(end-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8903610-7859-45aa-9342-699f473a2137",
   "metadata": {},
   "source": [
    "### Load Front Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "26087c42-945c-40a5-a7e3-432943362dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT created_at, page_type, page_data FROM front_pages WHERE \n",
      "          created_at >= \"2018-01-01 00:00:00\" AND\n",
      "          created_at <= \"2018-04-17 00:00:00\"\n",
      "    ORDER BY created_at ASC;\n",
      "\n",
      "72126 front pages loaded in 28 seconds\n"
     ]
    }
   ],
   "source": [
    "all_front_pages = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "front_page_query = text(\"\"\"\n",
    "SELECT created_at, page_type, page_data FROM front_pages WHERE \n",
    "          created_at >= \"{0}\" AND\n",
    "          created_at <= \"{1}\"\n",
    "    ORDER BY created_at ASC;\n",
    "\"\"\".format(earliest_date,\n",
    "           latest_date))\n",
    "print(front_page_query)\n",
    "\n",
    "for row in db_engine.execute(front_page_query):\n",
    "    page = {}\n",
    "    page['post_ranking'] = json.loads(row['page_data'])\n",
    "    page['created'] = row['created_at']\n",
    "    page['page_type'] = row['page_type']\n",
    "    all_front_pages.append(page)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"{0} front pages loaded in {1} seconds\".format(len(all_front_pages), int(end-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c606d153-4a91-49ed-a095-8b9cf4687a33",
   "metadata": {},
   "source": [
    "# Merge Posts, Comments, and Mod Actions\n",
    "Cover the period from January through April 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c241b05-1ee9-4c88-ab9d-a1eb9420e906",
   "metadata": {},
   "source": [
    "## Step one: sort all comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a67b551a-c2f9-4211-9da2-e1a07cdb5e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = utc.localize(datetime.datetime.utcfromtimestamp(0))\n",
    "\n",
    "class CommentHeapObj(object):\n",
    "    def __init__(self, comment):\n",
    "        ## localize the timezone if the field is not localized\n",
    "        try:\n",
    "            self.index = int((pytz.utc.localize(comment['created']) - EPOCH).total_seconds())\n",
    "        except:\n",
    "            self.index = int((comment['created'] - EPOCH).total_seconds())\n",
    "            \n",
    "        self.val = comment\n",
    "    def __lt__(self, other):\n",
    "        return self.index < other.index\n",
    "\n",
    "def heapsort(comments):\n",
    "    h = []\n",
    "    for comment in comments:\n",
    "        heapq.heappush(h, CommentHeapObj(comment))\n",
    "    return [heapq.heappop(h).val for i in range(len(h))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "25c4e21a-f40b-4bf5-ae2d-8a4c0bfbd8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments = heapsort(all_comments)\n",
    "recent_mod_actions = heapsort(recent_mod_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383c11a1-ad86-4991-81de-b2c784e45128",
   "metadata": {},
   "source": [
    "## Step Two: apply mod actions to comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "e7b31e07-7a6a-4982-9154-3d8064016103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7197 Total moderation actions\n",
      "4631 Comments with moderation actions\n",
      "2330 Comments with more than one mod action\n",
      "\n",
      "2602 Posts with moderation actions\n",
      "1694 Posts with more than one mod action\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mod_comment_actions = defaultdict(list)\n",
    "mod_post_actions    = defaultdict(list)\n",
    "\n",
    "approved_count = 0\n",
    "removed_count = 0\n",
    "total_coments_removed_at_least_once = []\n",
    "comments_with_mod_actions = set()\n",
    "posts_with_mod_actions    = set()\n",
    "\n",
    "for action in recent_mod_actions:\n",
    "     if action['action'] == \"removecomment\" or action['action'] == \"approvecomment\":\n",
    "            comment_id = action['target_fullname'].replace(\"t1_\", \"\")\n",
    "            mod_comment_actions[comment_id].append(action)\n",
    "            comments_with_mod_actions.add(action['target_fullname'].replace(\"t1_\", \"\"))\n",
    "\n",
    "     if action['action'] == \"removelink\" or action['action'] == \"approvelink\":\n",
    "            post_id = action['target_fullname'].replace(\"t3_\", \"\")\n",
    "            mod_post_actions[post_id].append(action)\n",
    "            posts_with_mod_actions.add(post_id)\n",
    "\n",
    "print(\"{0} Total moderation actions\".format(sum([len(x) for x in mod_comment_actions.values()])))\n",
    "print(\"{0} Comments with moderation actions\".format(len(mod_comment_actions)))\n",
    "print(\"{0} Comments with more than one mod action\".format(len([x for x in mod_comment_actions.values() if len(x)>1])))\n",
    "print(\"\")\n",
    "print(\"{0} Posts with moderation actions\".format(len(mod_post_actions)))\n",
    "print(\"{0} Posts with more than one mod action\".format(len([x for x in mod_post_actions.values() if len(x)>1])))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dfc4ee05-0ee2-42d2-9f79-fe070144591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(mod_comment_actions.values())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9db8df6b-129e-4ab4-9355-6c9850bcd5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now iterate through all comments and apply mod actions\n",
    "\n",
    "comments_by_post = defaultdict(list)\n",
    "counter = 0\n",
    "\n",
    "for comment in all_comments:\n",
    "    if comment['id'] in comments_with_mod_actions:\n",
    "        mod_actions =  mod_comment_actions[comment['id']]\n",
    "        visible = True\n",
    "        for action in mod_actions:\n",
    "            if action['action'] == 'removecomment':\n",
    "                visible = False\n",
    "                counter += 1\n",
    "            elif action['action'] == 'approvecomment':\n",
    "                visible = True\n",
    "    else:\n",
    "        visible = True\n",
    "    comment['visible'] = visible \n",
    "    comments_by_post[comment['post_id']].append(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "9f0af28b-adf0-4993-b2ee-51274e600e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3109 comments not in the observed set, attached to 711 posts.\n"
     ]
    }
   ],
   "source": [
    "## now iterate through \"ghost\" comments that received mod actions\n",
    "## but did not appear in the comments dataset, likely because they\n",
    "## were excised by the Reddit platform entirely\n",
    "\n",
    "observed_comment_ids = set([x['id'] for x in all_comments])\n",
    "modaction_comments_by_post = defaultdict(list)\n",
    "\n",
    "counter = 0\n",
    "for comment_id, mod_actions in mod_comment_actions.items():\n",
    "    if comment_id not in observed_comment_ids:\n",
    "        for action in mod_actions:\n",
    "            if action['action'] == 'removecomment':\n",
    "                visible = False\n",
    "            elif action['action'] == 'approvecomment':\n",
    "                visible = True\n",
    "\n",
    "        ## now extract the post ID:\n",
    "        post_id = re.sub(r'\\/.*', '', action['target_permalink'].replace(\"/r/Feminism/comments/\",\"\"))\n",
    "\n",
    "        comment = {\n",
    "            \"id\": action['target_fullname'].replace(\"t1_\",\"\"),\n",
    "            \"author\": action['target_author'],\n",
    "            \"visible\": visible,\n",
    "            \"body\": action['target_body'],\n",
    "            \"post_id\": post_id\n",
    "        }\n",
    "        modaction_comments_by_post[post_id].append(comment)\n",
    "        \n",
    "        counter +=1\n",
    "print(\"Found {0} comments not in the observed set, attached to {1} posts.\".format(counter, \n",
    "                                                                                  len(modaction_comments_by_post)))\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "b5a4b689-3b22-4dbc-a15b-922441b4f88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed removed comments from 451 posts that ARE NOT in the dataset.\n",
      "Observed removed comments from 260 posts that ARE in the dataset.\n"
     ]
    }
   ],
   "source": [
    "## How many posts are not in the post dataset\n",
    "## and how many posts have comments that aren't\n",
    "## in the comments dataset?\n",
    "all_post_ids = set([x['id'] for x in all_posts])\n",
    "Counter([x in all_post_ids for x in modaction_comments_by_post.keys()])\n",
    "\n",
    "print(\"Observed removed comments from {0} posts that ARE NOT in the dataset.\".format(\n",
    "    len(\n",
    "        [x for x in modaction_comments_by_post.keys() if (x in all_post_ids) is not True]\n",
    ")))\n",
    "\n",
    "print(\"Observed removed comments from {0} posts that ARE in the dataset.\".format(\n",
    "    len(\n",
    "        [x for x in modaction_comments_by_post.keys() if x in all_post_ids]\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaf8777-e02b-47eb-afa3-430a7afe7267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f29e94a6-a48f-44bb-b2a4-4f96cc8c2c52",
   "metadata": {},
   "source": [
    "## Step Three: Merge Comments Into Posts and Apply Mod Actions\n",
    "\n",
    "Note that we omit posts that are not observed in the dataset since it is likely that these posts **do** exist but were published in a period long before the observation period, and consequently are out of scope. In such a situation, someone might have come back months or years later to post spam to the post, which led to a content removal. It is also possible in some cases that those posts were too quickly auto-removed to be observed, but we are not able to confirm this with the available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "626968c6-9a20-4a8b-a1fd-5814dfe85eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied 969 additional unobserved comments from mod actions\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "posts_with_mod_actions_in_list = []\n",
    "\n",
    "\n",
    "### TODO: add all removed comments that only appear in mod actions\n",
    "\n",
    "total_unobserved_comments_applied = 0\n",
    "\n",
    "for post in all_posts:\n",
    "    visible = True\n",
    "    time_removed = None\n",
    "\n",
    "    post_id = post['id']\n",
    "    \n",
    "    if post_id in posts_with_mod_actions:\n",
    "        counter += 1\n",
    "        posts_with_mod_actions_in_list.append(post_id)\n",
    "        mod_actions = mod_post_actions[post_id]\n",
    "        for mod_action in mod_actions:\n",
    "            if mod_action['action'] == \"removelink\":\n",
    "                visible = False\n",
    "                time_removed = mod_action['created']\n",
    "            if mod_action['action'] == \"approvelink\":\n",
    "                visible = True\n",
    "                time_removed = None\n",
    "\n",
    "    post['num_comments'] = len(comments_by_post[post_id])\n",
    "    post['num_comments_removed'] = len([x for x in comments_by_post[post_id] if x['visible'] == False])\n",
    "    post['visible'] = visible\n",
    "    post['time_removed'] = time_removed\n",
    "\n",
    "    if post_id in modaction_comments_by_post.keys():\n",
    "        for comment in modaction_comments_by_post[post_id]:\n",
    "            total_unobserved_comments_applied += 1\n",
    "\n",
    "            post['num_comments'] += 1\n",
    "            if(comment['visible'] == False):\n",
    "                post['num_comments_removed'] += 1\n",
    "\n",
    "print(\"Applied {0} additional unobserved comments from mod actions\".format(total_unobserved_comments_applied)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "95cf22df-b366-485f-826b-aeb7d8512caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post_id_found = [x['id'] in list(comments_by_post.keys()) for x in all_posts]\n",
    "# Counter(post_id_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "03a5b445-0f4d-47b1-bb1f-218e7e21052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = list(comments_by_post.keys())\n",
    "# all_posts[0]['id'] in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "56e40a40-3485-4d66-9101-1500c1782598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_posts[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "d5c92ed9-b8f7-4a1d-a61c-77cf2802a969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5916"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x['target_body'] for x in recent_mod_actions if x['action']=='removecomment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "5854d1e5-8112-4629-9a09-d541a157c679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 679 out of 912 posts\n"
     ]
    }
   ],
   "source": [
    "end_date = utc.localize(parser.parse(\"2018-04-01\"))\n",
    "posts_for_analysis = [x for x in all_posts if \n",
    "                      x['created'] < end_date]\n",
    "print(\"Selected {0} out of {1} posts\".format(len(posts_for_analysis), len(all_posts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2b5e26-0422-442f-a970-0058eb45d383",
   "metadata": {},
   "source": [
    "### Step Four: Apply Maximum Rank Position Analysis to posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "f6064e33-ccdf-47e9-99e6-74b02f108967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "produced rank records for 1 r/feminism posts\n"
     ]
    }
   ],
   "source": [
    "## note: lower number means a higher rank\n",
    "## and there are four algorithms monitored\n",
    "def max_rank_record():\n",
    "    return {1:None, 2:None,3:None, 4:None}\n",
    "max_rank_per_post = defaultdict(max_rank_record)\n",
    "\n",
    "for rankings in all_front_pages:\n",
    "    algorithm_key = rankings['page_type']\n",
    "    for post_ranking in rankings['post_ranking']:\n",
    "        counter = 0\n",
    "        if post_ranking['subreddit_id'].replace(\"t5_\",\"\") == subreddit_id:\n",
    "            post_id = post_ranking['id']\n",
    "            rank_record = max_rank_per_post[post_id]\n",
    "            if(rank_record[algorithm_key] is None or \n",
    "               rank_record[algorithm_key] > counter):\n",
    "                rank_record[algorithm_key] = counter\n",
    "        counter += 1\n",
    "        \n",
    "print(\"produced rank records for {0} r/feminism posts\".format(len(max_rank_per_post)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf534d6-14be-43d8-9621-e72fbfa598c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "9aede41b-69a6-40c6-b71b-9698d9dec725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this post does not appear in the all_posts list so we omit doing the merge\n",
    "# for post_id, rank_record in max_rank_per_post.items():\n",
    "#     if post_id in "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d9008c-51a6-4680-aaf3-52ad6fa61f3d",
   "metadata": {},
   "source": [
    "# Output post records to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "b569060e-ad12-49db-a9a4-248fac9c990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_posts_anonymized = []\n",
    "\n",
    "for post in all_posts:\n",
    "    included_keys = ['subreddit_id', 'created', 'visible', 'num_comments', 'num_comments_removed', 'permalink', 'title']\n",
    "    anonymized_post = {}\n",
    "    for key in included_keys:\n",
    "        anonymized_post[key] = post[key]\n",
    "    all_posts_anonymized.append(anonymized_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "42d2a73b-8dae-4e22-93a1-16c0d56792d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_posts[0]\n",
    "#Counter([x['num_comments'] for x in all_posts_anonymized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "f6266a47-9a7c-4ed8-acc3-528f5e2c818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(all_posts_anonymized).to_csv(datetime.datetime.utcnow().strftime(\"%Y-%m-%d\") + \n",
    "                                          \"-post-aggregation-spring-2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d5677e-391f-4b8a-ada7-7d8c4da7dc8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (praw7)",
   "language": "python",
   "name": "praw7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
